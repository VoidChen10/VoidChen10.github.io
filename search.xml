<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Spark-MLlib学习日记1：K-means聚类分析]]></title>
    <url>%2F2019%2F01%2F30%2FSpark-MLlib%E5%AD%A6%E4%B9%A0%E6%97%A5%E8%AE%B01%EF%BC%9AK-means%E8%81%9A%E7%B1%BB%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言作为该系列的第一篇文章，也是我正式步入机器学习的第一篇学习日记，想说几句话，机器学习跟普通编程不一样，门槛对于大多数人来说都是算比较高的。曾经我也在惊叹和好奇中望而却步，现在在大佬的推动下也是鼓起勇气正式开始学习，完成这个系列也是我2019的目标。由于公司用的是Spark，所以从Spark MLlib开始学起，不积硅步无以至千里，在这个系列我也会从简单一点地基础开始，一点点切实地去学习，希望看到这篇文章地小伙伴也能下定决心，一起攻克机器学习。 K-Means 聚类算法原理K-Means算法流程关于原理呢，我直接引用《使用Spark MLlib做K-mean聚类分析》里面的资料好了： 聚类分析是一个无监督学习 (Unsupervised Learning) 过程, 一般是用来对数据对象按照其特征属性进行分组，经常被应用在客户分群，欺诈检测，图像分析等领域。K-means 应该是最有名并且最经常使用的聚类算法了，其原理比较容易理解，并且聚类效果良好，有着广泛的使用。 和诸多机器学习算法一样，K-means 算法也是一个迭代式的算法，其主要步骤如下: 第一步，选择 K 个点作为初始聚类中心。 第二步，计算其余所有点到聚类中心的距离，并把每个点划分到离它最近的聚类中心所在的聚类中去。在这里，衡量距离一般有多个函数可以选择，最常用的是欧几里得距离 (Euclidean Distance), 也叫欧式距离,公式如下：其中 C 代表中心点，X 代表任意一个非中心点。 第三步，重新计算每个聚类中所有点的平均值，并将其作为新的聚类中心点。 最后，重复 (二)，(三) 步的过程，直至聚类中心不再发生改变，或者算法达到预定的迭代次数，又或聚类中心的改变小于预先设定的阀值。 光这么看有点不是很直观，其实就是不断换聚类中心以求达到“最合理”的分类的过程，下面我贴一张数据可视化的图，更直观地描述这个过程： 如图，k-means算法在每一次迭代中，选择了更靠谱的红蓝中心点，试图让分类更合理，跟均匀。 欧式距离欧几里得公式的含义还是比较简单的，但是一开始看还是有点懵，在这里我稍微提一下自己的理解，如果不对的话欢迎留言指正=。=首先我们先回顾一下那个公式，那个n代表的是什么呢？ 我们先来看看欧式距离在二维和三维中的展开：是不是觉得很熟悉咧，就是求坐标之间的距离嘛，以此类推，在4维空间5维空间或者更高维度的空间中怎么算两点坐标距离呢？那就是原版的欧式距离公式啦！n在我看来，就是代表所求的维度数嘛，对应到实际应用中，这个“维度”对应的就是我们想要聚类的对象的参数。当n个参数可以确定一个唯一（或近似）的对象，我们通过欧式距离公式计算这个对象坐标的距离，把最后n维空间坐标相近的对象聚到同一个类别里，就完成了K-Means聚类算法要做的工作了。 聚类测试数据集在本文中，我们所用到目标数据集是来自UCI Machine Learning Repository的Wholesale customer Data Set。UCI是一个关于机器学习测试数据的下载中心站点，里面包含了适用于做聚类，分群，回归等各种机器学习问题的数据集。Wholesale customer Data Set是引用某批发经销商的客户在各种类别产品上的年消费数。为了方便处理，本文把原始的CSV格式转化成了两个文本文件，取前面20行作为测试集，其余的数据作为训练集。如图： 代码样例看注释就好了，基本就是处理好数据，然后调用spark-lib包里面的kmeans方法去做训练就ok了，源码分析大概会在做完这个系列之后再考虑要不要做。。。值得注意的是：val clusters:KMeansModel = KMeans.train(parsedTrainingData, numClusters, numIterations,runTimes)这行代码，我来介绍一下这几个参数： parsedTrainingData： 处理好的训练数据集 numClusters： 聚类的个数。这个值的选取有点学问，K的选择是K-means算法的关键，Spark MLlib在KMeansModel类里提供了computeCost方法，我的demo中也有该方法调用例子。该方法通过计算所有数据点到其最近的中心点的平方和来评估聚类的效果。一般来说，同样的迭代次数和算法跑的次数，这个值越小代表聚类的效果越好。但是在实际情况下，我们还要考虑到聚类结果的可解释性，不能一味的选择使computeCost结果值最小的那个K numIterations： K-means算法的迭代次数 runTimes： K-means算法run的次数 完整代码如下：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889/** * @author Chenyl * @date 2019/1/23 15:57 */import org.apache.spark.&#123;SparkContext, SparkConf&#125;import org.apache.spark.mllib.clustering.&#123;KMeans, KMeansModel&#125;import org.apache.spark.mllib.linalg.Vectorsobject KMeansClustering &#123; def main (args: Array[String]) &#123; val trainingPath = &quot;src/main/resources/Wholesale customers data_training.txt&quot; //训练数据集文件路径 val testPath = &quot;src/main/resources/Wholesale customers data_test.txt&quot; //测试数据集文件路径 val numClusters = 8 //聚类的个数 val numIterations = 30 //K-means 算法的迭代次数 val runTimes = 3 //K-means 算法 run 的次数 val conf = new SparkConf().setAppName(&quot;Spark MLlib Exercise:K-Means Clustering&quot;) conf //TODO: 生成打包前，需注释掉此行 .setMaster(&quot;local[*]&quot;) .set(&quot;spark.serializer&quot;, &quot;org.apache.spark.serializer.KryoSerializer&quot;) val sc = new SparkContext(conf) sc.setLogLevel(&quot;ERROR&quot;) //设置日志级别，info会有很多运行日志出现，也可以打开看看 /** *Channel Region Fresh Milk Grocery Frozen Detergents_Paper Delicassen * 2 3 12669 9656 7561 214 2674 1338 * 2 3 7057 9810 9568 1762 3293 1776 * 2 3 6353 8808 7684 2405 3516 7844 */ val rawTrainingData = sc.textFile(trainingPath) //加载测试数据 //去表头处理 val parsedTrainingData = rawTrainingData.filter(!isColumnNameLine(_)).map(line =&gt; &#123; Vectors.dense(line.split(&quot;\t&quot;).map(_.trim).filter(!&quot;&quot;.equals(_)).map(_.toDouble)) &#125;).cache()// findK(parsedTrainingData) // Cluster the data into two classes using KMeans var clusterIndex:Int = 0 //使用K-Means训练 val clusters:KMeansModel = KMeans.train(parsedTrainingData, numClusters, numIterations,runTimes) println(&quot;Cluster Number:&quot; + clusters.clusterCenters.length) println(&quot;Cluster Centers Information Overview:&quot;) clusters.clusterCenters.foreach(x =&gt; &#123; println(&quot;Center Point of Cluster &quot; + clusterIndex + &quot;:&quot;) println(x) clusterIndex += 1 &#125;) //begin to check which cluster each test data belongs to based on the clustering result val rawTestData = sc.textFile(testPath) //加载测试数据 val parsedTestData = rawTestData.map(line =&gt;&#123; Vectors.dense(line.split(&quot;\t&quot;).map(_.trim).filter(!&quot;&quot;.equals(_)).map(_.toDouble)) &#125;) parsedTestData.collect().foreach(testDataLine =&gt; &#123; val predictedClusterIndex: Int = clusters.predict(testDataLine) //使用训练好的模型进行分类 println(&quot;The data &quot; + testDataLine.toString + &quot; belongs to cluster &quot; +predictedClusterIndex) &#125;) println(&quot;Spark MLlib K-means clustering test finished.&quot;) &#125; private def isColumnNameLine(line:String):Boolean = &#123; if (line != null &amp;&amp; line.contains(&quot;Channel&quot;)) true else false &#125; /** * 查看最佳的K值 * @param parsedTrainingData */ private def findK(parsedTrainingData:org.apache.spark.rdd.RDD[org.apache.spark.mllib.linalg.Vector]): Unit =&#123; val ks:Array[Int] = Array(3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20) ks.foreach(cluster =&gt; &#123; val model:KMeansModel = KMeans.train(parsedTrainingData, cluster,30,1) val ssd = model.computeCost(parsedTrainingData) println(&quot;sum of squared distances of points to their nearest center when k=&quot; + cluster + &quot; -&gt; &quot;+ ssd) &#125;) &#125;&#125;]]></content>
      <categories>
        <category>Spark-MLlib学习日记</category>
      </categories>
      <tags>
        <tag>spark</tag>
        <tag>MachineLeaning</tag>
        <tag>K-Means</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kerberos探索遇到的问题及心得]]></title>
    <url>%2F2019%2F01%2F27%2FKerberos%E6%8E%A2%E7%B4%A2%E9%81%87%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98%E5%8F%8A%E5%BF%83%E5%BE%97%2F</url>
    <content type="text"><![CDATA[Kerberos在集群开启时做了什么kerberos在浪潮集群中启动时会自动安装clien端，此时它会针对每个服务以及机器创建对应得Principal，这些principal也将创建成Linux内的用户。 注意，这些用户将只存在于创建这些用户的机器上 关于Hive执行HQL时count(*)会出错 Hive跟HDFS一样，在集群开启Kerberos后不需要特别的设置即可使用，然而在试图执行 1select count( * ) from test 时，会出现以下报错: 原因便是上面提到的，创建的用户只在创建的机器上有，而Hive这个count其实是启动了一个MapReduce在集群上跑，集群上其他的机器没有nassoft_m这个账号，所以报错说找不到用户名。 解决办法： &ensp;&ensp;&ensp;&ensp;在每台机都加上nassoft_m这个账号即可 关于Hive遇到的权限问题 hive很多操作都是对HDFS的，而hdfs默认文件权限为drwxr-xr-x ，即文件创建者拥有全权限，同组及其他用户只拥有读取权限，然而我们登陆的principal很多情况下都不是文件创建者，所以在kerberos启动的情况下使用hive，又时会出现权限不足的报错，就是因为hive可能对hdfs进行了写入操作。 解决办法： &ensp;&ensp;&ensp;&ensp;把nassoft_m账号添加到hdfs用户组里，然后使用chmod 777(或者774)命令修改权限 查看zookeeper节点认证失败 解决办法：在zkCli.sh 中加入 1JVMFLAGS=&quot;-Djava.security.auth.login.config=/usr/hdp/2.6.4.0-91/zookeeper/conf/zookeeper_jaas.conf&quot; 关于Hbase出现的权限不足报错认证后在hbase中使用命令行出现如下错误： 解决办法：给相应的用户分配权限1grant &apos;nassoft_r&apos;,&apos;RWXCA&apos; 关于kafka在Kerberos中的使用命令行稍有变化 生产者端命令为：bin/kafka-console-producer.sh –broker-list hd2.bigdata:6667 –topic test_wifi2 –producer.config conf/producer.properties –security-protocol SASL_PLAINTEXT 消费者端命令为：bin/kafka-console-consumer.sh –bootstrap-server hd2.bigdata:6667 –from-beginning –topic test_wifi2 conf/consumer.properties –security-protocol SASL_PLAINTEXT 另外就是java代码中需要添加以下配置：12345678System.setProperty(&quot;java.security.krb5.conf&quot;, &quot;E:\\krb5.conf&quot;);System.setProperty(&quot;java.security.auth.login.config&quot;, &quot;E:\\kafka_client_jaas.conf&quot;);Properties props = new Properties();props.put(&quot;security.protocol&quot;, &quot;SASL_PLAINTEXT&quot;);props.put(&quot;sasl.mechanism&quot;, &quot;GSSAPI&quot;);props.put(&quot;sasl.kerberos.service.name&quot;, &quot;kafka&quot;);...... 需要从服务器下载以下3个文件： krb5.conf kafka_client_jaas.conf kafka.service.keytab 其中kafka_client_jaas.conf稍作修改：1234567891011121314151617181920Client&#123; com.sun.security.auth.module.Krb5LoginModule required doNotPrompt=true useTicketCache=true principal=&quot;kafka/hd2.bigdata@HADOOP.COM&quot; useKeyTab=true serviceName=&quot;zookeeper&quot; keyTab=&quot;E:\\kafka.service.keytab&quot; client=true;&#125;;KafkaClient &#123; com.sun.security.auth.module.Krb5LoginModule required doNotPrompt=true useTicketCache=true principal=&quot;kafka/hd2.bigdata@HADOOP.COM&quot; useKeyTab=true serviceName=&quot;kafka&quot; keyTab=&quot;E:\\kafka.service.keytab&quot; client=true;&#125;; solr的相关问题12Kinit nassoft_mcurl --negotiate -u : &quot;http://hd1.bigdata:8983/solr/&quot; 解决方法：1234server/scripts/cloud-scripts/zkcli.sh -zkhost hd2.bigdata:2181,master2.bigdata:2181,master1.bigdata:2181 -cmd put /security.json &apos;&#123;&quot;authentication&quot;:&#123;&quot;class&quot;: &quot;org.apache.solr.security.KerberosPlugin&quot;&#125;&#125;&apos;刷新solr keytab修改 keytab 权限重启solr集群 curl --negotiate -u : &quot;http://hd1.bigdata:8983/solr/&quot;成功]]></content>
      <categories>
        <category>集群</category>
      </categories>
      <tags>
        <tag>Keeberos</tag>
        <tag>集群安全</tag>
      </tags>
  </entry>
</search>
